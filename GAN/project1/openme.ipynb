{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"openme.ipynb","provenance":[],"collapsed_sections":["aWLa31_HyM_-","XY97lgL1w3B7","2XADscdfeW1L","GdRv3j5TVVku","Ji7SSk0-VBYS","dzMiITy6Py6f","KH4UgmbwIvlM"],"authorship_tag":"ABX9TyOdL6ILhmkq+WG5iWJitIy8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"aWLa31_HyM_-"},"source":["# 1. Initial Setup\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9eIHehCMX6-e"},"source":["\n","*   connect to Google Drive\n","*   specify project folder\n","*   check GPU and project version"]},{"cell_type":"markdown","metadata":{"id":"xATEiBJVXTdW"},"source":["a. Connect to Google Drive. Here we allow the colab notebook access to your google drive."]},{"cell_type":"code","metadata":{"id":"FGh3AuRWoDrC"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kDZuzL3PXmox"},"source":["b. Specify the **folder name** below. This also needs to be specified in the \"Config\" section"]},{"cell_type":"code","metadata":{"id":"Py1EQDd54GRU"},"source":["folder_name = \"project1\"  \n","\n","#don't edit me:\n","from IPython.display import Audio\n","scripts_dir = \"/content/drive/My Drive/GAN/\" + folder_name +\"/scripts\"\n","bleep = scripts_dir + '/beep.wav'\n","%cd $scripts_dir\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iyQMS1MmXx6t"},"source":["c. This cell is to check our runtime type and project version.\n","\n","  The statement should say \"using **cuda** for computation\". If not go to Runtime < change runtime type and select \"GPU\".\n"]},{"cell_type":"code","metadata":{"id":"Ic_SCfTNicCK"},"source":["%run version_ctrl.py\n","%run check_gpu.py\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XY97lgL1w3B7"},"source":["#2. Data Processing & Training Images\n","\n","\n","\n"," \n","\n"]},{"cell_type":"markdown","metadata":{"id":"axpdJR4tgnQa"},"source":["This is for processing raw data (images and videos) in our Google Drive into a form that our model can use. This only needs to be done **once**.  \n","\n","a. Add Images and Videos into \"data/raw/\" folder (formats allowed: jpeg, png, mp4, avi, mkv)\n","\n","b.  Adjust **colour** and **delta_t** paramters and run the cell\n","\n","\n","\n","> To convert images to B&W set **colour=0**, otherwise leave **colour=1** \n","\n","\n","> Frames are taken from the video every **delta_t** seconds and processed as images.\n","\n","\n","> Images are center cropped to a **square format** and compressed to **128x128 pixels**.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"kwu-YhFNS0qa"},"source":["colour = 1            # 0 for B&W  ; 1 for colour\n","\n","delta_t = 1           # time interval between video frame grabs (seconds) \n","\n","%run process_data.py {colour} {delta_t}\n","Audio(bleep, autoplay=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"swFGoO8ITOLP"},"source":["**View** the processed images:"]},{"cell_type":"code","metadata":{"id":"bXAJDqvlwZ5M"},"source":["%run dataloader_init.py\n","Audio(bleep, autoplay=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M2zBOxfUU29u"},"source":["\n","If you are happy with the processed images, **delete** the contents of the \"**data/raw**\" folder. \n","\n","You can then add more images/videos here and repeat steps a and b\n"," if you want to add to your training images dataset."]},{"cell_type":"markdown","metadata":{"id":"2XADscdfeW1L"},"source":["#3. Config.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YjqZHOEfYqeY"},"source":["Here we specify the variables for our model.\n","\n","Once specified we run the cell and this writes the variables to a file\n","\n","If changes are made we need to **restart runtime** (Runtime < restart runtime) and rerun the cell **b** in **1. Initial Setup** "]},{"cell_type":"code","metadata":{"id":"UVNxWN_eiIs5"},"source":["\n","%%writefile config.py\n","\n","#BASIC SETTINGs:\n","\n","folder_name = \"project1\"\n","\n","image_size = 64   #size of images created in pixels ie 64x64 pixels. Values available: {8,16,32,64,128}\n","\n","nc = 3            # Number of channels in the training images. For color images this is 3. For black and white use 1\n","\n","nz = 100          #Size of z latent vector (generator input) \n","                  #for image_size = 32,64,128 use 50,100,400 respectively\n","\n","ngf = 64          # Size of feature maps in generator;\n","                  # set to image_size, unless image_size =128, then set to 64\n","\n","ndf = 64          # Size of feature maps in discriminator;\n","                  # set to image_size. Unless image_size =128, then set to 32\n","\n","\n","#ADVANCED SETTINGS:\n","\n","\n","workers = 8         # Number of workers for dataloader\n","\n","batch_size = 128    # Batch size during training\n","\n","lr = 0.0002         # Learning rate for optimizers\n","\n","beta1 = 0.5         # Beta1 hyperparam for Adam optimizers\n","\n","ngpu = 1            # Number of GPUs available. Use 0 for CPU mode.\n","\n","lsf = 0.2           # label softening factor  fake= 0:lsf; real = (1-lsf): 1\n","\n","\n","#DON'T EDIT! ...\n","\n","root_dir = \"/content/drive/My Drive/GAN/\" + folder_name +\"/\"\n","dataset_dir = root_dir + \"data/processed/\"\n","rawdata_dir = root_dir + \"data/raw/\"\n","video_dir = root_dir + \"video/\"\n","model_dir = root_dir + 'model/'\n","script_dir = root_dir + 'scripts/'\n","checkpoint_path = root_dir + 'checkpoint/checkpoint.tar'\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GdRv3j5TVVku"},"source":["# 4. Train your Model\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"J59F3W3fXwAr"},"source":["Here we train our model for a specified number of **epochs**.\n","\n","An epoch is when the model has cycled through all our training images once.\n","\n","The more we train our model the better it becomes (usually) at generating images "]},{"cell_type":"markdown","metadata":{"id":"9lmRUZhVRH1T"},"source":["**START or RESTART** training:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"IqlxgM5RH3Yg"},"source":["epochs = 25\n","\n","%run train.py False {epochs}\n","Audio(bleep, autoplay=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"srlL1mroRdqW"},"source":["**CONTINUE** training:\n","\n"]},{"cell_type":"code","metadata":{"id":"j54IB5XmXG4L"},"source":["epochs = 100\n","\n","%run train.py True {epochs}\n","Audio(bleep, autoplay=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7lMsFmlsw4os"},"source":["plot a **graph** to check the quality of the training: "]},{"cell_type":"code","metadata":{"id":"7MUxj2GbXgsu"},"source":["# plot training loss\n","%run plot_loss.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ji7SSk0-VBYS"},"source":["# 5. See Generated Images"]},{"cell_type":"markdown","metadata":{"id":"ge5ZxtciV-Lt"},"source":["Show **64 samples** of images generated by the model:"]},{"cell_type":"code","metadata":{"id":"ZLO24AzcuZut"},"source":["%run plot_fakes.py 15"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2AhUiDAtWN8Q"},"source":["Show a **single** sample:\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"yvdtUHp4xFuu"},"source":["%run plot_fake.py 8"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dzMiITy6Py6f"},"source":["# 6. Make a Movie!"]},{"cell_type":"markdown","metadata":{"id":"KxVOtk0kZvGv"},"source":["Here we make a movie by sequencing our generated images at 24 frames per second.\n","\n","Our movie consists of **transitioning** between generated samples (like those in section 5.) \n","\n","The **smoothing** variable defines how gradual (or \"smooth\") this transition will be.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"s30EZAr05-Rn"},"source":["movie_name = \"movie1\"\n","\n","fps = 24          # frames per second\n","smoothing = 3.0     # duration between samples (seconds)\n","duration= 30     # movie length in (seconds)\n","\n","%run make_movie.py {movie_name} {fps} {smoothing} {duration}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RFMERNYBLGre"},"source":["Once you're happy with your movie, you can increase the resolution x16 by running the below:"]},{"cell_type":"code","metadata":{"id":"jc3u_Z8UAEik"},"source":["#run only once\n","!pip install ISR"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RbBvGPz5I_u0"},"source":["%run make_movie_isr.py {movie_name} {fps} {smoothing} {duration}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KH4UgmbwIvlM"},"source":["# Save/ Load Model"]},{"cell_type":"markdown","metadata":{"id":"wVUU-Rr4v4Aw"},"source":["If you are happy with the results, give your model a name and save it. You can then load at a later date and continue to train or make movies with it."]},{"cell_type":"code","metadata":{"id":"yMJf5NR6U9MZ"},"source":["#SAVE MODEL\n","\n","model_name = \"model1\"\n","\n","%run save_model.py {model_name}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JhGZ0ViRO-5V"},"source":["#LOAD MODEL\n","\n","model_name = \"model1\"\n","\n","%run load_model.py {model_name}"],"execution_count":null,"outputs":[]}]}